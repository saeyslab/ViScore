{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting ViScore benchmark results\n",
    "\n",
    "> **&copy; David Novak 2024**, see [LICENSE](https://github.com/saeyslab/ViScore/blob/main/LICENSE)\n",
    "\n",
    "Once our [benchmark](https://github.com/saeyslab/ViScore/tree/main/benchmarking) is completed, we will want to report the results somehow.\n",
    "This notebook will help you create tables and informative figures to that end.\n",
    "\n",
    "We will need a Python environment with ViScore, its dependencies, `funkyheatmappy` and `adjustText`.\n",
    "`funkyheatmappy` and `adjustText` are installed using the following command in shell/Anaconda Prompt:\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/funkyheatmap/funkyheatmappy.git\n",
    "pip install git+https://github.com/Phlya/adjustText.git\n",
    "```\n",
    "\n",
    "We assume that you followed instructions in `ViScore/benchmarking/README.md` for designing and running your benchmark.\n",
    "In accordance with that, we assume that\n",
    "\n",
    "* results of benchmark are stored in `./results`\n",
    "* all datasets listed in `./datasets.txt` were used\n",
    "* all methods listed in `./config.json` were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, copy, pandas as pd, json, numpy as np, matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have an opportunity to adjust the colour palette per cell population to use in plotting embeddings directly and the marker symbols and colours used for each DR method in plotting structure-preservation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_pops = [\n",
    "    '#726ca6','#8ff56b','#79d0f9','#fba56a','#eefc85','#aeaead','#6e85ff','#b97671','#dbbafd','#6bb277',\n",
    "    '#6af1b0','#b26ae7','#fb6c98','#fdc4b8','#c1c86c','#699dc0','#d889c1','#a89ef4','#95d598','#757469',\n",
    "    '#78fefe','#f1f7c3','#b2ddfb','#cad9a3','#9b9f69','#aa7caa','#74c7c0','#face7e','#fe9cdb','#ce9f81',\n",
    "    '#bafc85','#fdd5f1','#e97f6c','#8d89d7','#839095','#d68ef9','#a5d1ca','#d1fcfe','#6eaaee','#f799a1',\n",
    "    '#d7b2c8','#70d87a','#99faa9','#6b70d4','#dbd8d2','#fb77c9','#88f4d2','#d17a98','#90b2d3','#aafef7',\n",
    "    '#debc9d','#d2e96a','#96c96a','#8c6ff5','#927286','#7cff8e','#80b19e','#adbcfa','#d86fdd','#aee276',\n",
    "    '#eee1a5','#feb6fe','#996dc9','#b699cc','#ad908d','#76946b','#d2fea8','#a7b883','#b881fe','#69e7da',\n",
    "    '#92e8f5','#b5b6d4','#dadcfa','#bf6cbe','#9199b6','#70d79f','#6afd6e','#dcb26c','#d69fae','#b5eab1',\n",
    "    '#fce96a','#6987aa','#8dadfc','#938afd','#c7ebe4','#de6a7f','#938669','#c4cce8','#e36daf','#e8f1e8',\n",
    "    '#86e1b6','#ff6b69','#ed9ffc','#87d7d6','#feb58d','#b96a93','#dcd189','#adc9a7'\n",
    "]\n",
    "palette_methods = ['orange',      # PCA \n",
    "                   'teal',        # UMAP\n",
    "                   'darkmagenta', # DensMAP\n",
    "                   'darkblue',    # tSNE\n",
    "                   'maroon',      # PHATE\n",
    "                   '#404040',     # PaCMAP\n",
    "                   'firebrick',   # TriMap\n",
    "                   'darkkhaki',   # SQuad-MDS\n",
    "                   'olivedrab',   # VAE\n",
    "                   'plum',        # ivis\n",
    "                   'darkorange',  # ViVAE\n",
    "                   'darkred'      # ViVAE-EncoderOnly\n",
    "]\n",
    "markers_methods = ['o', # PCA\n",
    "                   '^', # UMAP\n",
    "                   'v', # DensMAP\n",
    "                   's', # tSNE\n",
    "                   'o', # PHATE\n",
    "                   '^', # PaCMAP\n",
    "                   'v', # TriMap\n",
    "                   's', # SQuad-MDS\n",
    "                   'o', # VAE\n",
    "                   '^', # ivis\n",
    "                   'v', # ViVAE\n",
    "                   's'  # ViVAE-EncoderOnly\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.** Collecting results\n",
    "\n",
    "We start by aggregating quantitative results.\n",
    "\n",
    "* The `rnx`, `sl` and `sg` dictionaries will contain denoised and non-denoised RNX, Local SP and Global SP values for all method-dataset combinations.\n",
    "* The `df_all` dataframe will contain all Local SP, Global SP and Balanced SP (using either geometric mean or harmonic mean) per method-dataset-denoising combination, for each run (random seed).\n",
    "* The `df_avg` dataframe will contain mean and standard-deviation values, aggregated across runs.\n",
    "* The `df_time` dataframe will contain mean standard-deviation values for running times required for training, aggregated across runs.\n",
    "\n",
    "<hr>\n",
    "\n",
    "The first step is to determine the datasets and methods used in this benchmark.\n",
    "**If this is anything other than what is indicated in `./datasets.txt` and `./config.json`, you will need to adapt this manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_datasets = './datasets.txt'\n",
    "with open(fname_datasets, 'r') as f:\n",
    "  datasets = [line.strip() for line in f.readlines()]\n",
    "fname_config = './config.json'\n",
    "with open(fname_config, encoding='utf-8') as f:\n",
    "    conf = json.load(f)\n",
    "methods = list(conf['methods'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to specify:\n",
    "\n",
    "* Which target dimensionality we are working with (`zdim`).\n",
    "\n",
    "* How many repeated runs of each set-up we have (`nruns`).\n",
    "\n",
    "* Whether we are working with results for denoised inputs. The `denoised` variable can be `False` (use results on non-denoised data), `True` (use results on denosied data) or `'ViVAE'` (only use denoised data results for ViVAE: this is what ViVAE was designed for).\n",
    "**Crucially, this does not mean ViVAE is evaluated against denoised inputs (this would be an unfair comparison): it is evaluated the same way all other methods are.**\n",
    "\n",
    "* Whether to use `'geometric_mean'` or `'harmonic_mean'`  for computing balanced (local-global) structure preservation. There is a case to be made for either, but the more comprehensive way to look at results is to plot both Local and Global SP in a biaxial plot (which we also do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdim = 2\n",
    "nruns = 5\n",
    "denoised = 'ViVAE'\n",
    "balanced_measure = 'harmonic_mean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load some helper and plotting functions from an auxiliary script (they are mostly documented and should be easy to tweak if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "from aux import collect_dicts, collect_df_avg, collect_df_all, collect_df_times_avg, get_denoised_mask, prepare_denoising_data\n",
    "\n",
    "## Plotting\n",
    "from aux import plot_separate_sp, plot_sp_tradeoffs, fh, plot_funky_heatmap, plot_rnx_curves, plot_embeddings, plot_denoising_sp_change, plot_denoising_rnx_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnx, sl, sg = collect_dicts(datasets, methods, zdim=zdim, nruns=nruns)\n",
    "df_avg      = collect_df_avg(datasets, methods, nruns=nruns, zdim=zdim, balanced_measure=balanced_measure, wide=True)\n",
    "df_all      = collect_df_all(datasets, methods, nruns=nruns, zdim=zdim, balanced_measure=balanced_measure, wide=True)\n",
    "df_time     = collect_df_times_avg(datasets, methods, nruns=nruns, zdim=zdim, wide=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a 'report' directory where outputs will be saved (unless it already exists).\n",
    "**If you already generated outputs for a previous benchmark using this notebook, they will eventually be overwritten.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./report'):\n",
    "    os.mkdir('./report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.** Plotting structure-preservation values\n",
    "\n",
    "We will plot the Local, Global and Balanced SP using scatterplots with errorbars for separate categories and a scatterplot showing the Local-Global trade-off.\n",
    "By default, we take results for ViVAE run on de-noised inputs and results for other methods on original inputs.\n",
    "This is because ViVAE was designed specifically to work with the de-noising, which is part of the algorithm.\n",
    "However, it is fair to also the effects of de-noising on SP by other methods (this amounts to an ablation experiment), so we also do that below.\n",
    "\n",
    "<hr>\n",
    "\n",
    "First, the separate plotting of Local, Global and Balanced SP, using points with error bars (mean and standard deviation), separately also for each dataset.\n",
    "This is not the easiest plot to look at, but we use it to show the standard deviations as indicators of stability.\n",
    "\n",
    "The figure is exported as a PNG and SVG file: `report/01_sp_separate.[png|svg]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_separate_sp(datasets, methods, df_all, palette=palette_methods)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we plot the trade-off/balance between Local and Global using a scatter plot.\n",
    "We do this dataset by dataset, using the *x*-axis for Local SP, the *y*-axis for Global SP.\n",
    "\n",
    "The Pareto front is indicated, so that the reader can easily check which methods offer a favourable trade-off between the two criteria.\n",
    "(Note that this **does not** mean that any methods not on the Pareto front in your benchmark are not useful or summarily worse than the other methods!\n",
    "There are many ways to evaluate a method, depending on the type of analysis we're doing.\n",
    "Also, while using a decent number of datasets to evaluate a method on increases the informativeness of a benchmark, this is still an empirical evaluation that may give different results on different datasets.)\n",
    "\n",
    "The figure is exported as a PNG file: `report/01_sp_tradeoffs.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plot_sp_tradeoffs(datasets, methods, df_avg, df_all, palette_methods, markers_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.** Plotting structure preservation in a heatmap\n",
    "\n",
    "As an additional visualisation method, we use a [funky heatmap](https://funkyheatmap.github.io/funkyheatmap/) to plot Local, Global and Balanced SP.\n",
    "This is not included in our paper, but for large benchmarks it is a nice way of plotting quantitative results.\n",
    "In order for things to work correctly for us, we monkey-patched some functions in the `funkyheatmappy` module (see `aux.py`).\n",
    "\n",
    "We define a `plot_funky_heatmap` function.\n",
    "The `geom` argument determines the visualisation technique for all scores.\n",
    "It can be set to `'bar'`, `'funkyrect'` or `'circle'`.\n",
    "\n",
    "**The plotted values are min-max scaled for each of the 3 categories.\n",
    "Otherwise, if `scale_column` is set to True, values are scaled per column.**\n",
    "\n",
    "The figure is exported as a PNG and SVG file: `report/02_funky_heatmap.[png|svg]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plot_funky_heatmap(df_avg, datasets, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.** Plotting $R_{NX}$ curves\n",
    "\n",
    "The $R_{\\mathrm{NX}}$ curve approximations (from which Local and Global SP are calculated) can be plotted directly for each dataset and method, and we can show the effect of de-noising as well.\n",
    "\n",
    "The figure is exported as a PNG and SVG file: `report/03_rnx_curves.[png|svg]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plot_rnx_curves(rnx, datasets, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.** Plotting labelled embeddings\n",
    "\n",
    "We create a plot of embeddings of all datasets by all tested methods, with points coloured by labelled cell populations, and export it as a PNG file: `report/04_embeddings.png`.\n",
    "Legends for the colour scheme will be saved separately for each dataset in `report/04_legends`.\n",
    "\n",
    "SVG files are not generated here, because they might be huge (depending on sizes of embedded datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plot_embeddings(datasets, methods, palette_pops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.** Plotting effects of denoising\n",
    "\n",
    "Our ViVAE pipeline includes nearest neighbour-based denoising ('smoothing') of inputs prior to training the model on them.\n",
    "This typically results in local structures being better preserved in the embedding by ViVAE.\n",
    "Our estimation is that we force ViVAE to model truly important structures and not get overwhelmed by spurious noise patterns.\n",
    "\n",
    "However, in our study we are interested in what effect this denoising might have on other DR methods.\n",
    "In particular, VAE-based methods often benefit from denoising.\n",
    "\n",
    "To document this, we report the effects of denoising for all methods and datasets, as an ablation study.\n",
    "\n",
    "We plot the difference in $R_{NX}$ curves for each method and dataset with and without denoising, and the Local and Global SP shift due to denoising.\n",
    "\n",
    "**Only run code in this section if you tested denoising also.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnx_lims, l_vals0, l_vals1, l_diffs, g_vals0, g_vals1, g_diffs, l_diff_lims, g_diff_lims = prepare_denoising_data(datasets, methods, rnx, sl, sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plot_denoising_rnx_change(datasets, methods, rnx)\n",
    "plot_denoising_sp_change(datasets, methods, l_diffs, g_diffs, l_diff_lims, g_diff_lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.** Creating tables with structure-preservation results\n",
    "\n",
    "We generate a table with SP results in two formats: LaTeX and CSV.\n",
    "\n",
    "<hr>\n",
    "\n",
    "LaTeX is perhaps the best way to report numerical results in a report or paper.\n",
    "**However, you might need to do some formatting tweaks to make it look nice.**\n",
    "\n",
    "If the `highlight_best` argument is set to `True`, we put the best average score per dataset in each category in bold.\n",
    "\n",
    "The LaTeX code is saved in a text file: `report/06_results_table.txt`.\n",
    "This code can be used in a `.tex` file.\n",
    "The `longtable` package, and perhaps some other ones, need to be loaded for the source file to compile.\n",
    "The easiest way to compile is via [Overleaf](https://www.overleaf.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_best=True\n",
    "nruns=5\n",
    "label='tab:sp'\n",
    "\n",
    "caption=f\"\"\"Mean and standard deviation values from {nruns} runs of each set-up are reported.\n",
    "Entries with highest mean value per dataset are in bold.\"\"\"\n",
    "\n",
    "d = copy.deepcopy(df_avg)\n",
    "\n",
    "if highlight_best:\n",
    "    idcs_best_localsp = []\n",
    "    idcs_best_globalsp = []\n",
    "    idcs_best_balancedsp = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    idcs = np.where(d['Dataset']==dataset)[0]\n",
    "    idcs_best_localsp.append(idcs[np.argmax(d['LocalSP_Mean'][idcs])])\n",
    "    idcs_best_globalsp.append(idcs[np.argmax(d['GlobalSP_Mean'][idcs])])\n",
    "    idcs_best_balancedsp.append(idcs[np.argmax(d['BalancedSP_Mean'][idcs])])\n",
    "\n",
    "d['Denoising'] = ['On' if x==True else 'Off' for x in d['Denoised']]\n",
    "d['Local SP']  = [f'${np.round(d[\"LocalSP_Mean\"][i], 3)} \\\\pm {np.round(d[\"LocalSP_SD\"][i], 3)}$' for i in range(d.shape[0])]\n",
    "d['Global SP'] = [f'${np.round(d[\"GlobalSP_Mean\"][i], 3)} \\\\pm {np.round(d[\"GlobalSP_SD\"][i], 3)}$' for i in range(d.shape[0])]\n",
    "d['Balanced SP'] = [f'${np.round(d[\"BalancedSP_Mean\"][i], 3)} \\\\pm {np.round(d[\"BalancedSP_SD\"][i], 3)}$' for i in range(d.shape[0])]\n",
    "\n",
    "d = d[['Dataset', 'Method', 'Denoising', 'Local SP', 'Global SP', 'Balanced SP']]\n",
    "\n",
    "if highlight_best:\n",
    "    for i in idcs_best_localsp:\n",
    "        s = d['Local SP'][i]\n",
    "        d['Local SP'][i] = re.sub('\\$$', '}$', re.sub('^\\$', r'$\\\\mathbf{', s))\n",
    "    for i in idcs_best_globalsp:\n",
    "        s = d['Global SP'][i]\n",
    "        d['Global SP'][i] = re.sub('\\$$', '}$', re.sub('^\\$', r'$\\\\mathbf{', s))\n",
    "    for i in idcs_best_balancedsp:\n",
    "        s = d['Balanced SP'][i]\n",
    "        d['Balanced SP'][i] = re.sub('\\$$', '}$', re.sub('^\\$', r'$\\\\mathbf{', s))\n",
    "\n",
    "## Merge adjacent cells containing method names\n",
    "\n",
    "for method in methods:\n",
    "    idcs = np.where(d['Method']==method)[0]\n",
    "\n",
    "    idcs_multirow = np.array([idcs[i] for i in range(len(idcs)) if np.mod(i, 2)==0])\n",
    "    idcs_empty = np.array([idcs[i] for i in range(len(idcs)) if np.mod(i, 2)==1])\n",
    "\n",
    "    d['Method'][idcs_multirow] = '\\\\multirow{2}{*}{'+method+'}'\n",
    "    d['Method'][idcs_empty] = ''\n",
    "\n",
    "## Merge adjacent cells containing dataset names\n",
    "\n",
    "for dataset in datasets:\n",
    "    idcs = np.where(d['Dataset']==dataset)[0]\n",
    "    n = len(idcs)\n",
    "    d['Dataset'][idcs[0]] = '\\\\multirow{'+str(n)+'}{*}{'+dataset+'}'\n",
    "    for i in range(1, n):\n",
    "        d['Dataset'][idcs[i]] = ''\n",
    "\n",
    "## Make LaTeX code\n",
    "d = d.set_index('Dataset', append=True).swaplevel(0, 1)\n",
    "code = d.to_latex(index=True)\n",
    "\n",
    "## Make table page-breakable\n",
    "code = code.replace('begin{tabular}', 'begin{longtable}')\n",
    "code = code.replace('end{tabular}', 'end{longtable}')\n",
    "\n",
    "## Fix alignment of rows and colums\n",
    "code = re.sub(pattern='} \\& [0-9]+ \\&', repl='} &', string=code)\n",
    "code = re.sub(pattern='\\\\\\\\\\n \\& [0-9]+ \\&', repl='\\\\\\\\\\n &', string=code)\n",
    "code = re.sub(pattern='\\&  \\& Method', repl='& Method', string=code)\n",
    "code = code.replace('$ \\\\\\\\\\n\\\\cline{1-7}\\n\\\\multirow[t]', '$ \\\\\\\\\\n\\\\multirow[t]')\n",
    "code = code.replace('\\n & Method & De-noising & Local SP & Global SP & Balanced SP \\\\\\\\\\nDataset &', '\\n Dataset & Method & De-noising & Local SP & Global SP & Balanced SP \\\\\\\\\\n &')\n",
    "code = code.replace('\\\\bottomrule\\n', '')\n",
    "\n",
    "## Add caption and label\n",
    "code = code.replace('\\\\end{longtable}', '\\\\caption{'+caption+'}\\n\\\\label{'+label+'}\\n\\\\end{longtable}')\n",
    "\n",
    "## Adjust font size\n",
    "code = '{\\n\\\\renewcommand{\\\\arraystretch}{0.45}\\n\\\\tiny'+code+'}'\n",
    "\n",
    "## Save as textfile\n",
    "with open('./report/06_results_table.txt', 'w') as text_file:\n",
    "    text_file.write(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a CSV file with the same information.\n",
    "CSV files are easy to read programatically, and can thus be used for making custom plots.\n",
    "Additionally, if your results table is too large to fit on a single page of a manuscript, you will likely need to include a stand-alone CSV or Excel file anyway.\n",
    "\n",
    "The CSV file is saved as `report/06_results_table.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.to_csv('./report/06_results_table.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.** Creating tables with running times\n",
    "\n",
    "We also create a LaTeX and CSV table that aggregates the running time of each set-up.\n",
    "\n",
    "This generates `report/07_times_table.txt` and `report/07_times_table.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns=5\n",
    "label='tab:times'\n",
    "\n",
    "caption=f\"\"\"Mean and standard deviation values for running times from {nruns} runs of each set-up are reported.\"\"\"\n",
    "\n",
    "d = copy.deepcopy(df_time)\n",
    "\n",
    "d['Denoising'] = ['On' if x==True else 'Off' for x in d['Denoised']]\n",
    "d['RunningTime']  = [f'${np.round(d[\"RunningTime_Mean\"][i], 1)}\\\\pm {np.round(d[\"RunningTime_SD\"][i], 1)}$' for i in range(d.shape[0])]\n",
    "\n",
    "d = d[['Dataset', 'Method', 'Denoising', 'RunningTime']]\n",
    "\n",
    "## Merge adjacent cells containing method names\n",
    "for method in methods:\n",
    "    idcs = np.where(d['Method']==method)[0]\n",
    "\n",
    "    idcs_multirow = np.array([idcs[i] for i in range(len(idcs)) if np.mod(i, 2)==0])\n",
    "    idcs_empty = np.array([idcs[i] for i in range(len(idcs)) if np.mod(i, 2)==1])\n",
    "\n",
    "    d['Method'][idcs_multirow] = '\\\\multirow{2}{*}{'+method+'}'\n",
    "    d['Method'][idcs_empty] = ''\n",
    "\n",
    "## Merge adjacent cells containing dataset names\n",
    "for dataset in datasets:\n",
    "    idcs = np.where(d['Dataset']==dataset)[0]\n",
    "    n = len(idcs)\n",
    "    d['Dataset'][idcs[0]] = '\\\\multirow{'+str(n)+'}{*}{'+dataset+'}'\n",
    "    for i in range(1, n):\n",
    "        d['Dataset'][idcs[i]] = ''\n",
    "\n",
    "## Adjust headers\n",
    "code = code.replace('Dataset & Method & Denoising & RunningTime', 'Dataset & Method & De-noising & Running time (seconds)')\n",
    "\n",
    "## Make LaTeX code\n",
    "code = d.to_latex(index=False)\n",
    "\n",
    "## Make table page-breakable\n",
    "code = code.replace('begin{tabular}', 'begin{longtable}')\n",
    "code = code.replace('end{tabular}', 'end{longtable}')\n",
    "\n",
    "## Adjust formatting\n",
    "code = code.replace('\\\\\\\\\\n\\\\multirow{'+str(len(methods)*2)+'}{*}', '\\\\\\\\\\n\\\\cline{1-4}\\n\\\\multirow{'+str(len(methods)*2)+'}{*}')\n",
    "\n",
    "## Add caption and label\n",
    "code = code.replace('\\\\end{longtable}', '\\\\caption{'+caption+'}\\n\\\\label{'+label+'}\\n\\\\end{longtable}')\n",
    "\n",
    "\n",
    "## Adjust font size\n",
    "code = '{\\n\\\\renewcommand{\\\\arraystretch}{0.45}\\n\\\\tiny'+code+'}'\n",
    "\n",
    "## Save as textfile\n",
    "with open('./report/07_times_table.txt', 'w') as text_file:\n",
    "    text_file.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.to_csv('./report/07_times_table.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
