{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing single-cell data for a benchmark (out-of-core with Zarr)\n",
    "\n",
    "This is an alternative to the `00_prepare_dataset.ipynb` notebook that uses [Zarr](https://zarr.dev) for an out-of-core pre-processing workflow.\n",
    "This is useful if you don't have enough RAM to hold the single-cell expression data in memory (not enough RAM).\n",
    "\n",
    "At the moment this assumes that normalised expression data (not raw counts) is extracted.\n",
    "\n",
    "**Please use a separate conda environment for this:**\n",
    "\n",
    "```\n",
    "conda create -n zarr python=3.9\n",
    "conda activate zarr\n",
    "pip install zarr scanpy numpy==1.26.4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidnovak/miniforge3/envs/ViVAE/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/davidnovak/miniforge3/envs/ViVAE/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/davidnovak/miniforge3/envs/ViVAE/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/davidnovak/miniforge3/envs/ViVAE/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/davidnovak/miniforge3/envs/ViVAE/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/davidnovak/miniforge3/envs/ViVAE/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/davidnovak/miniforge3/envs/ViVAE/lib/python3.11/site-packages/anndata/utils.py:434: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc, anndata as ad, numpy as np, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = 'Suo'\n",
    "output_path = './data'\n",
    "batch_size = 1000\n",
    "colname = 'cell_type'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -O ./scrnaseq.h5ad https://datasets.cellxgene.cziscience.com/62b18ca2-6956-49f1-8b6d-0885fb38e1ac.h5ad >/dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = sc.read_h5ad('./scrnaseq.h5ad')\n",
    "hd.write_zarr('scrnaseq.zarr')\n",
    "del hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_zarr('scrnaseq.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908046 cells, 33145 genes\n"
     ]
    }
   ],
   "source": [
    "n_obs, n_vars = adata.shape\n",
    "print(f'{n_obs} cells, {n_vars} genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 909/909 [03:22<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "mean = np.zeros(n_vars)\n",
    "M2 = np.zeros(n_vars)\n",
    "count = 0\n",
    "\n",
    "for start in tqdm(range(0, n_obs, batch_size)):\n",
    "    end = min(start + batch_size, n_obs)\n",
    "    X = adata.X[start:end]\n",
    "    if not isinstance(X, np.ndarray):\n",
    "        X = X.toarray()\n",
    "    count += X.shape[0]\n",
    "    delta = X - mean\n",
    "    mean += np.sum(delta, axis=0) / count\n",
    "    delta2 = X - mean\n",
    "    M2 += np.sum(delta * delta2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.sqrt(M2 / (count - 1))\n",
    "std[std == 0] = 1.0  # prevent division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = IncrementalPCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Incremental PCA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 909/909 [5:04:09<00:00, 20.08s/it]    \n"
     ]
    }
   ],
   "source": [
    "print('Fitting Incremental PCA...')\n",
    "for start in tqdm(range(0, n_obs, batch_size)):\n",
    "    end = min(start + batch_size, n_obs)\n",
    "    X = adata.X[start:end]\n",
    "    if not isinstance(X, np.ndarray):\n",
    "        X = X.toarray()\n",
    "    X_scaled = (X - mean) / std\n",
    "    ipca.partial_fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data into PCA space...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 909/909 [05:18<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "pcs = []\n",
    "print('Transforming data into PCA space...')\n",
    "for start in tqdm(range(0, n_obs, batch_size)):\n",
    "    end = min(start + batch_size, n_obs)\n",
    "    X = adata.X[start:end]\n",
    "    if not isinstance(X, np.ndarray):\n",
    "        X = X.toarray()\n",
    "    X_scaled = (X - mean) / std\n",
    "    pcs.append(ipca.transform(X_scaled))\n",
    "\n",
    "pcs = np.concatenate(pcs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 908046-by-100 PC matrix\n"
     ]
    }
   ],
   "source": [
    "np.save(os.path.join(output_path, f'{dataset_name}_input.npy'), pcs, allow_pickle=True)\n",
    "print(f'Saved {pcs.shape[0]}-by-{pcs.shape[1]} PC matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_zarr('scrnaseq.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 908046-label vector with 66 unique labels\n"
     ]
    }
   ],
   "source": [
    "unassigned = []\n",
    "\n",
    "labels = adata.obs[colname]\n",
    "np.save(os.path.join(output_path, f'{dataset_name}_labels.npy'), labels, allow_pickle=True)\n",
    "np.save(os.path.join(output_path, f'{dataset_name}_unassigned.npy'), unassigned, allow_pickle=True)\n",
    "print(f'Saved {len(labels)}-label vector with {len(np.unique(labels))} unique labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, restart the kernel, switch to your ViScore conda environment, run the first code cell and return here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 150-nearest-neighbour graph\n"
     ]
    }
   ],
   "source": [
    "import viscore as vs, numpy as np, os\n",
    "\n",
    "pcs = np.load(os.path.join(output_path, f'{dataset_name}_input.npy'), allow_pickle=True)\n",
    "k = 150\n",
    "\n",
    "knn = vs.make_knn(x=pcs, k=k, fname=os.path.join(output_path, f'{dataset_name}_knn.npy'), verbose=False)\n",
    "print(f'Saved {k}-nearest-neighbour graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved denoised PC matrix\n"
     ]
    }
   ],
   "source": [
    "pcs_d = vs.smooth(pcs, knn, k=100, coef=1., n_iter=1)\n",
    "np.save(os.path.join(output_path, f'{dataset_name}_inpu_denoised.npy'), pcs_d, allow_pickle=True)\n",
    "print('Saved denoised PC matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = vs.make_knn(x=pcs_d, k=150, fname=os.path.join(output_path, f'{dataset_name}_knn_denoised.npy'), verbose=False)\n",
    "print(f'Saved denoised {k}-nearest-neighbour graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
